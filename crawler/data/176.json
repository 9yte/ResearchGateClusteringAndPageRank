{"abs":"Many recent and often adaptive Markov Chain Monte Carlo (MCMC) methods are associated in practice to unknown rates of convergence. We propose a simulation-based methodology to estimate MCMC efficiency, grounded on a Kullback divergence criterion requiring an estimate of the entropy of the algorithm successive densities, computed from iid simulated chains. We recently proved in Chauveau and Vandekerkhove (2013) some consistency results in MCMC setup for an entropy estimate based on Monte-Carlo integration of a kernel density estimate based on Gy√∂rfi and Van Der Meulen (1989). Since this estimate requires some tuning parameters and deteriorates as dimension increases, we investigate here an alternative estimation technique based on Nearest Neighbor estimates. This approach has been initiated by Kozachenko and Leonenko (1987) but used mostly in univariate situations until recently when entropy estimation has been considered in other fields like neuroscience. Theoretically, we prove that, under certain uniform control conditions, the successive densities of a generic class of Adaptive Metropolis-Hastings algorithms to which most of the strategies proposed in the recent literature belong can be estimated consistently with our method. We then show that in MCMC setup where moderate to large dimensions are common, this estimate seems appealing for both computational and operational considerations, and that the problem inherent to a non neglictible bias arising in high dimension can be overcome. All our algorithms for MCMC simulation and entropy estimation are implemented in an R package taking advantage of recent advances in high performance (parallel) computing.","title":"The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation","id":279260160,"url":"https://www.researchgate.net/publication/279260160_The_Nearest_Neighbor_entropy_estimate_an_adequate_tool_for_adaptive_MCMC_evaluation","names":["Didier Chauveau","Pierre Vandekerkhove"],"references":{"1759003":"Convergence of adaptive mixtures of importance sampling schemes","3082726":"A Nonparametric Estimation of the Entropy for Absolutely Continuous Distributions","3079783":"Best asymptotic normality of the kernel density entropy estimator for smooth densities","224437354":"Fast Multidimensional Entropy Estimation by -d Partitioning","49458431":"A tutorial on adaptive MCMC","268854217":"An entropy estimate based on a kernel density estimation","243768404":"Nonparametric Entropy Estimation: An Overview","267986090":"Smoothness of Metropolis-Hastings algorithm and application to entropy estimation","31403274":"Monte Carlo Sampling Methods Using Markov Chains and Their Application","245810545":"Coupling and Ergodicity of Adaptive MCMC","51916417":"A central limit theorem for adaptive and interacting Markov chains","38326865":"Optimal Scaling for Various Metropolis-Hastings Algorithms","224407609":"Divergence Estimation for Multidimensional Densities Via -Nearest-Neighbor Distances","41035177":"Accelerating Markov Chain Monte Carlo Simulation by Differential Evolution with Self-Adaptive Randomized Subspce Sampling","228573825":"Divide and Conquer: A Mixture-Based Approach to Regional Adaptation for MCMC","228636543":"On the Containment Condition for Adaptive Markov Chain Monte Carlo Algorithms","265465075":"Tweedie, R.L.: Rates of convergence of the Hastings and Metropolis algorithms. Ann. Stat. 24, 101-121","224877317":"Equation of State Calculations by Fast Computing Machines","274015857":"Team RDC.R: A Language And Environment For Statistical Computing. R Foundation for Statistical Computing: Vienna, Austria","226182428":"Convergence of Markov Chains in Information Divergence","221960533":"Ensemble Estimators for Multivariate Entropy Estimation","268243405":"Sample estimate of entropy of a random vector","23633488":"Geometric convergence of the Metropolis-Hastings simulation algorithm","239582331":"Stochastic Relaxation, Gibbs Distributions and the Bayesian Resoration of Images","233824019":"Nearest Neighbor Estimates of Entropy"},"citedIn":{},"index":176}