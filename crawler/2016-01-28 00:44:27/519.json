{"abs":"In this article we focus on Maximum Likelihood estimation (MLE) for the static parameters of hidden Markov models (HMMs). We will consider the case where one cannot or does not want to compute the conditional likelihood density of the observation given the hidden state because of increased computational complexity or analytical intractability. Instead we will assume that one may obtain samples from this conditional likelihood and hence use approximate Bayesian computation (ABC) approximations of the original HMM. ABC approximations are biased, but the bias can be controlled to arbitrary precision via a parameter \\epsilon\u003e0; the bias typically goes to zero as \\epsilon \\searrow 0. We first establish that the bias in the log-likelihood and gradient of the log-likelihood of the ABC approximation, for a fixed batch of data, is no worse than \\mathcal{O}(n\\epsilon), n being the number of data; hence, for computational reasons, one might expect reasonable parameter estimates using such an ABC approximation. Turning to the computational problem of estimating $\\theta$, we propose, using the ABC-sequential Monte Carlo (SMC) algorithm in Jasra et al. (2012), an approach based upon simultaneous perturbation stochastic approximation (SPSA). Our method is investigated on two numerical examples","title":"Static Parameter Estimation for ABC Approximations of Hidden MarkovModels","id":232272875,"url":"https://www.researchgate.net/publication/232272875_Static_Parameter_Estimation_for_ABC_Approximations_of_Hidden_MarkovModels","names":["Elena Ehrlich","Ajay Jasra","Nikolas Kantas"],"references":{"4217606":"On-Line Parameter Estimation in General State-Space Models","221667313":"On Disturbance State-Space Models and the Particle Marginal Metropolis-Hastings Sampler","252722201":"The Inventory and Distribution of Baryons at Redshift z\u003d0","51892293":"Asymptotic Behaviour of Approximate Bayesian Estimators","228338569":"An Adaptive Sequential Monte Carlo Method for Approximate Bayesian Computation","227423577":"Exponential forgetting and geometric ergodicity for optimal filtering in general state-space models","227464467":"Particle approximations of the score and observed information matrix in state space models with application to parameter estimation","51932281":"Linear Variance Bounds for Particle Approximations of Time-Homogeneous Feynman-Kac Formulae","227859894":"Approximate Bayesian Computation for Smoothing","48174205":"Forward Smoothing using Sequential Monte Carlo","29617444":"A non asymptotic variance theorem for unnormalized Feynman-Kac particle models","253024700":"Expectation-Propagation for Summary-Less, Likelihood-Free Inference","224640271":"Gradient-free maximum likelihood parameter estimation with particle filters","2559189":"On Sequential Monte Carlo Sampling Methods for Bayesian Filtering","225404508":"Filtering via approximate Bayesian computation","50855792":"Parameter Estimation for Hidden Markov Models with Intractable\nLikelihoods","236853542":"Inference in Hidden Markov Models","258683539":"Sequential State and Observation Noise Covariance Estimation Using Combined Ensemble Kalman and Particle Filters","216301469":"Introduction to Stochastic Search and Optimization","233990793":"Feynman-Kac Formulae: Genealogical and Interacting Particle Systems With Applications","51911139":"Uniform Stability of a Particle Approximation of the Optimal Filter\nDerivative","1924769":"Sharp failure rates for the bootstrap particle filter in high dimensions","51962726":"Error Bounds and Normalizing Constants for Sequential Monte Carlo in\nHigh Dimensions","226755642":"The ensemble Kalman filter is an ABC algorithm","4993330":"Sequential Monte Carlo Samplers"},"citedIn":{"227859894":"Approximate Bayesian Computation for Smoothing","258247203":"Particle filter-based Gaussian Process Optimisation for Parameter Inference"},"index":519}