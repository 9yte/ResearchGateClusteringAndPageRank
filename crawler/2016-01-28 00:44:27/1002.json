{"abs":"Mixtures of linear mixed models (MLMMs) are useful for clustering grouped data and can be estimated by likelihood maximization through the EM algorithm. The conventional approach to determining a suitable number of components is to compare different mixture models using penalized log-likelihood criteria such as BIC.We propose fitting MLMMs with variational methods which can perform parameter estimation and model selection simultaneously. A variational approximation is described where the variational lower bound and parameter updates are in closed form, allowing fast evaluation. A new variational greedy algorithm is developed for model selection and learning of the mixture components. This approach allows an automatic initialization of the algorithm and returns a plausible number of mixture components automatically. In cases of weak identifiability of certain model parameters, we use hierarchical centering to reparametrize the model and show empirically that there is a gain in efficiency by variational algorithms similar to that in MCMC algorithms. Related to this, we prove that the approximate rate of convergence of variational algorithms by Gaussian approximation is equal to that of the corresponding Gibbs sampler which suggests that reparametrizations can lead to improved convergence in variational algorithms as well.","title":"Variational Approximation for Mixtures of Linear Mixed Models","id":51966591,"url":"https://www.researchgate.net/publication/51966591_Variational_Approximation_for_Mixtures_of_Linear_Mixed_Models","names":["Siew Li Tan","David J. Nott","Journal of Computational and Graphical Statistics"],"references":{"4993356":"Clustering Using Objective Functions and Stochastic Search","51511570":"Sparse Variational Analysis of Linear Mixed Models for Large Data Sets.","24056046":"Comparing Partitions","226435002":"An Introduction to Variational Methods for Graphical Models","40453039":"Bayesian inference for generalized linear models. Biostatistics, 11, 397-412","222662604":"Variational approximations in Bayesian model selection for finite mixture distributions. Comput Stat Data Anal","45180090":"Clustering via Mixture Regression Models with Random Effects","7371134":"Generalized Hierarchical Multivariate CAR Models for Areal Data","1903443":"Variational Inference for Large-Scale Models of Discrete Choice","223748248":"Choosing starting values for the EM algorithm for getting the highest likelihood in multivariate Gaussian mixture models. Comput Stat Data Anal 41(3-4):561-575","13443714":"Eisen, M.B., Spellman, P.T., Brown, P.O. \u0026 Botstein, D. Cluster analysis and display of genome-wide expression patterns. Proc. Natl. Acad. Sci. USA 95, 14863−14868","12908437":"Systematic Determination of Genetic Network Architecture","4745818":"Vector Differential Calculus in Statistics","44843129":"Explaining Variational Approximations","38358303":"‘Estimating the Dimension of A Model,’","227376027":"Random effects mixture models for clustering electrical load series","220320310":"Variational Message Passing.","38357534":"On the Rate of Convergence of the ECM Algorithm","7106357":"A Mixture model with random-effects components for clustering correlated gene-expression profiles. Bioinformatics","235230687":"Integrated Genomic and Proteomic Analyses of a Systematically Perturbed Metabolic Network","3193130":"Assessing a mixture model for clustering with the integrated completed likelihood. IEEE Trans Pattern Anal Mach Intell","10771640":"Software Clustering gene-expression data with repeated measurements","11514381":"Mixture modelling of gene expression data from microarray experiments. Bioinformatics","227664115":"The EM Algorithm—An Old Folk Song Sung to a Fast New Tune (with Discussion)","10878087":"Clustering of time-course gene expression data using a mixed-effects model with B-splines. Bioinformatics","6307266":"Unsupervised Learning of Gaussian Mixtures Based on Variational Component Splitting","220286466":"A new variational Bayesian algorithm with application to human mobility pattern modeling","10896453":"Efficient Greedy Learning of Gaussian Mixture Models","43283696":"A Bayesian approach to multi-source forest area estimation","11679832":"Model-Based Clustering and Data Transformations for Gene Expression Data","11430530":"McLachlan GJ, Bean RW, Peel D. A mixture model-based approach to the clustering of microarray expression data. Bioinformatics 18: 413-422","224881739":"Inferring Parameters and Structure of Latent Variable Models by Variational Bayes","40812354":"Mixtures of Regression Models for Time-Course Gene Expression Data: Evaluation of Initialization and Random Effects","242923415":"On convergence of the EM algorithmand the Gibbs sampler","31186037":"Efficient Parametrisations for Normal Linear Mixed Models","233871583":"Bayesian Hierarchical Mixtures of Experts","228629648":"Mixture of Linear Mixed Models for Clustering Gene Expression Profiles from Repeated Microarray Experiments","1762088":"A General Framework for the Parametrization of Hierarchical Models","3027229":"A New Look At The Statistical Model Identification","33020867":"An Introduction to Variational Methods for Graphical Models","11042141":"Bayesian model search for mixture models based on optimizing variational bounds","246452549":"Inadequacy of interval estimates corresponding to variational Bayesian approximations","2446931":"Comprehensive Identification of Cell Cycle-regulated Genes of the Yeast Saccharomyces cerevisiae by Microarray Hybridization","246784707":"Maximum Likelihood from Incomplete Data via the EM Algorithm","233806999":"Adaptive Mixture of Local Expert","254295504":"Regression Density Estimation With Variational Methods and Stochastic Approximation","285934966":"On convergence of the EM algorithm and the Gibbs sampler"},"citedIn":{"224973111":"Variational Inference for Generalized Linear Mixed Models Using Partially Noncentered Parametrizations"},"index":1002}