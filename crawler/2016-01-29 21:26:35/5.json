{"abs":"Drawing a sample from a discrete distribution is one of the building components for Monte Carlo methods. Like other sampling algorithms, discrete sampling also suffers from high computational burden in large-scale inference problems. We study the problem of sampling a discrete random variable with a high degree of dependency that is typical in large-scale Bayesian inference and graphical models, and propose an efficient approximate solution with a subsampling approach. We make a novel connection between the discrete sampling and Multi-Armed Bandits problems with a finite reward population and provide three algorithms with theoretical guarantees. Empirical evaluations show the robustness and efficiency of the approximate algorithms in both synthetic and real-world large-scale problems.","title":"Subsampling-Based Approximate Monte Carlo for Discrete Distributions","id":279633530,"url":"https://www.researchgate.net/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions","names":["Yutian Chen","Zoubin Ghahramani"],"references":{"221996154":"Probability Inequalities For Sums of Bounded Random Variables","236235190":"Austerity in MCMC Land: Cutting the Metropolis-Hastings Budget","264948136":"A Sequential Multiple-Decision Procedure for Selecting the Best One of Several Normal Populations with a Common Unknown Variance, and Its Use with Various Experimental Designs","221618614":"The Tradeoffs of Large Scale Learning.","220286498":"Slice sampling mixture models","262350854":"Monte Carlo MCMC: efficient inference by approximate sampling","266660385":"Reducing the sampling complexity of topic models","215470704":"Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling","221346425":"Bayesian Learning via Stochastic Gradient Langevin Dynamics","225209253":"Optimum Follow the Leader Algorithm","262030260":"Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets","259478458":"lil\u0027 UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits","239551242":"Variance Reduction Techniques for Digital Simulation","221111135":"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models","235709950":"A Sequential Procedure for Selecting the Population with the Largest Mean from $k$ Normal Populations","2360567":"Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation","224175402":"Scaling the iHMM: Parallelization versus Hadoop","220343796":"Finite-time Analysis of the Multiarmed Bandit Problem","256606492":"Concentration inequalities for sampling without replacement","2779476":"Algorithms for Scoring Coreference Chains","243764505":"Bayesian Model Choice via Markov Chain Monte Carlo","38357750":"Probability Inequalities for the Sum in Sampling without Replacement","38350870":"Sensitivity and convergence of uniformly ergodic Markov chains","220320734":"Distributed Algorithms for Topic Models"},"citedIn":{},"index":5}