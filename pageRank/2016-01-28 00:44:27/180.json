{"abs":"We propose Kernel Hamiltonian Monte Carlo (KMC), a gradient-free adaptive MCMC algorithm based on Hamiltonian Monte Carlo (HMC). On target densities where classical HMC is not an option due to intractable gradients, KMC adaptively learns the target\u0027s gradient structure by fitting an exponential family model in a Reproducing Kernel Hilbert Space. Computational costs are reduced by two novel efficient approximations to this gradient. While being asymptotically exact, KMC mimics HMC in terms of sampling efficiency, and offers substantial mixing improvements over state-of-the-art gradient free samplers. We support our claims with experimental studies on both toy and real-world applications, including Approximate Bayesian Computation and exact-approximate MCMC.","title":"Gradient-free Hamiltonian Monte Carlo with Efficient Kernel Exponential Families","id":277959058,"url":"https://www.researchgate.net/publication/277959058_Gradient-free_Hamiltonian_Monte_Carlo_with_Efficient_Kernel_Exponential_Families","names":["Heiko Strathmann","Dino Sejdinovic","Samuel Livingstone","Zoltan Szabo","Arthur Gretton"],"references":{"239382660":"All of Nonparametric Statistics","2762543":"Adaptive proposal distribution for random walk Metropolis algorithm. Comput Stat","271855091":"The Fundamental Incompatibility of Hamiltonian Monte Carlo and Data Subsampling","224980705":"A Kernel Two-Sample Test","49458431":"A tutorial on adaptive MCMC","45630121":"Statistical inference for noisy nonlinear ecological dynamic systems","221620515":"Random Features for Large-Scale Kernel Machines","24168169":"The pseudo-marginal approach for effcient Monte Carlo computations","278733571":"Hamiltonian Monte Carlo Acceleration Using Neural Network Surrogate functions","49459410":"Low Rank Updates for the Cholesky Decomposition","265465075":"Tweedie, R.L.: Rates of convergence of the Hastings and Metropolis algorithms. Ann. Stat. 24, 101-121","277959344":"Optimal Rates for Random Fourier Features","243104985":"Coupling and ergodicity of adaptive Markov chain Monte Carlo algorithms. J Appl Probab","229058177":"Methods for Modifying Matrix Factorizations","220320841":"Estimation of Non-Normalized Statistical Models by Score Matching.","220055927":"Abstract Some extensions of score matching","2349384":"Geometric Convergence and Central Limit Theorems for Multidimensional Hastings and Metropolis Algorithms","264742891":"Fastfood: Approximate Kernel Expansions in Loglinear Time","221996875":"Kernel Method for Pattern Analysis","268820276":"Optimizing The Integrator Step Size for Hamiltonian Monte Carlo","45894926":"Likelihood-free Markov chain Monte Carlo","259288193":"Density Estimation in Infinite Dimensional Exponential Families","250613960":"Kernel Adaptive Metropolis-Hastings","10652634":"Beaumont MA. Estimation of population growth or decline in genetically monitored populations. Genetics 164: 1139-1160","260232379":"Stochastic Gradient Hamiltonian Monte Carlo","228926940":"Gaussian Processes to Speed up Hybrid Monte Carlo for Expensive Bayesian Integrals","8970227":"Markov Chain Monte Carlo without likelihoods","262954130":"Pseudo-Marginal Bayesian Inference for Gaussian Processes"},"citedIn":{"277959344":"Optimal Rates for Random Fourier Features"},"index":180}