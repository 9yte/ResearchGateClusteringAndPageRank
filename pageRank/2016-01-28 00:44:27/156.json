{"abs":"MCMC algorithms such as Metropolis-Hastings algorithms are slowed down by the computation of complex target distributions as exemplified by huge datasets. We offer in this paper a useful generalisation of the Delayed Acceptance approach, devised to reduce the computational costs of such algorithms by a simple and universal divide-and-conquer strategy. The idea behind the generic acceleration is to divide the acceptance step into several parts, aiming at a major reduction in computing time that out-ranks the corresponding reduction in acceptance probability. Each of the components can be sequentially compared with a uniform variate, the first rejection signalling that the proposed value is considered no further. We develop moreover theoretical bounds for the variance of associated estimators with respect to the variance of the standard Metropolis-Hastings and detail some results on optimal scaling and general optimisation of the procedure. We illustrate those accelerating features on a series of examples","title":"Accelerating Metropolis-Hastings algorithms by Delayed Acceptance","id":273157850,"url":"https://www.researchgate.net/publication/273157850_Accelerating_Metropolis-Hastings_algorithms_by_Delayed_Acceptance","names":["Marco Banterle","Clara Grazian","Anthony Lee","Christian P. Robert"],"references":{"238879805":"Markov chain Monte Carlo Using an Approximation","243765314":"Estimation of nite mixture distributions by Bayesian sampling","43481745":"Finite Mixture Model","46494018":"Efficient parallelisation of Metropolis-Hastings algorithms using a prefetching approach","259783208":"Delayed acceptance particle MCMC for exact inference in stochastic kinetic models","225635105":"Optimal Scaling of Random Walk Metropolis Algorithms with Non-Gaussian Proposals","2316151":"Bayesian Methods for Mixtures of Normal Distributions","2269174":"A Note on Metropolis-Hastings Kernels for General State Spaces","31081996":"Optimum Monte-Carlo Sampling Using Markov Chains","46154966":"CODA: Convergence diagnosis and output analysis for MCMC","258631741":"Asymptotically Exact, Embarrassingly Parallel MCMC","245810545":"Coupling and Ergodicity of Adaptive MCMC","2583743":"Weak Convergence And Optimal Scaling Of Random Walk Metropolis Algorithms","12826203":"Some adaptive Monte Carlo methods for Bayesian inference","247011232":"On Markov Chain Monte Carlo Acceleration","38326865":"Optimal Scaling for Various Metropolis-Hastings Algorithms","236597249":"MCMC for non-linear state space models using ensembles of latent sequences","227657870":"Riemann manifold Langevin and Hamiltonian Monte Carlo methods. J. R. Stat. Soc. B 73, 123-214","265465075":"Tweedie, R.L.: Rates of convergence of the Hastings and Metropolis algorithms. Ann. Stat. 24, 101-121","236235190":"Austerity in MCMC Land: Cutting the Metropolis-Hastings Budget","268209561":"M Carlo Statistical Methods","259334992":"Parallel MCMC via Weierstrass Sampler","2787469":"Markov Chain Monte Carlo Methods Based on `Slicing\u0027 the Density Function","2349384":"Geometric Convergence and Central Limit Theorems for Multidimensional Hastings and Metropolis Algorithms","257142847":"On the efficiency of pseudo-marginal random walk Metropolis algorithms","226460107":"Langevin Diffusions and Metropolis-Hastings Algorithms","5066743":"Reparameterisation Strategies for Hidden Markov Models and Bayesian Approaches to Maximum Likelihood Estimation.","2834582":"Scaling Limits for the Transient Phase of Local Metropolis-Hastings Algorithms","2821588":"Practical Bayesian Density Estimation Using Mixtures Of Normals"},"citedIn":{"274730206":"The Metropolisâ€”Hastings Algorithm"},"index":156}